{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Keras and other dependencies\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import other packges\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "Done\n",
      "0.005015134811401367\n",
      "      pixel0 pixel1 pixel2 pixel3 pixel4 pixel5 pixel6 pixel7 pixel8 pixel9  \\\n",
      "60000      0      0      0      0      0      0      0      0      0      0   \n",
      "\n",
      "        ...    pixel774 pixel775 pixel776 pixel777 pixel778 pixel779 pixel780  \\\n",
      "60000   ...           0        0        0        0        0        0        0   \n",
      "\n",
      "      pixel781 pixel782 pixel783  \n",
      "60000        0        0        0  \n",
      "\n",
      "[1 rows x 784 columns]\n",
      "Done1\n",
      "0.03961896896362305\n"
     ]
    }
   ],
   "source": [
    "import os,array\n",
    "import pandas as pd\n",
    "os.chdir('C:\\\\Users\\\\soumyama\\\\Documents\\\\Python Scripts\\\\personal tutorial\\\\AV\\\\FashionMNIST\\\\train')\n",
    "import time\n",
    "\n",
    "from PIL import Image\n",
    "columnNames = list()\n",
    "\n",
    "for i in range(784):\n",
    "    pixel = 'pixel'\n",
    "    pixel += str(i)\n",
    "    columnNames.append(pixel)\n",
    "\n",
    "\n",
    "train_data1 = pd.DataFrame(columns = columnNames)\n",
    "start_time = time.time()\n",
    "for i in range(60000,60001):\n",
    "    t = i\n",
    "    img_name = str(t)+'.png'\n",
    "    img = Image.open(img_name)\n",
    "    rawData = img.load()\n",
    "        #print rawData\n",
    "    data = []\n",
    "    for y in range(28):\n",
    "        for x in range(28):\n",
    "            data.append(rawData[x,y][0])\n",
    "    print(i)\n",
    "    k = 0\n",
    "        #print data\n",
    "    train_data1.loc[i] = [data[k] for k in range(784)]\n",
    "    #print train_data.loc[0]\n",
    "\n",
    "print(\"Done\")\n",
    "print(time.time()-start_time)\n",
    "\n",
    "#os.chdir('../../')\n",
    "#label_data = pd.read_csv(\"train.csv\")\n",
    "#print label_data\n",
    "#train_labels = label_data['label']\n",
    "#print label_data['label']\n",
    "#train_data = pd.concat([train_data,label_data],axis = 1)\n",
    "#train_data = train_data.drop('filename',1)\n",
    "print(train_data1)\n",
    "\n",
    "train_data1.to_csv(\"C:\\\\Users\\\\soumyama\\\\Documents\\\\Python Scripts\\\\personal tutorial\\\\AV\\\\FashionMNIST\\\\train_converted1.csv\",index = False)\n",
    "print(\"Done1\")\n",
    "print(time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>119</td>\n",
       "      <td>113</td>\n",
       "      <td>130</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>96</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  pixel0 pixel1 pixel2 pixel3 pixel4 pixel5 pixel6 pixel7 pixel8 pixel9  \\\n",
       "1      0      0      0      0      0      0      0      0      0      0   \n",
       "2      0      0      0      0      0      1      0      0      0      0   \n",
       "3      0      0      0      0      0      0      0      0      0     22   \n",
       "4      0      0      0      0      0      0      0      0     32     96   \n",
       "5      0      0      0      0      0      0      0      0      0      0   \n",
       "\n",
       "    ...    pixel774 pixel775 pixel776 pixel777 pixel778 pixel779 pixel780  \\\n",
       "1   ...           0        0        0        0        0        0        0   \n",
       "2   ...         119      113      130       76        0        0        0   \n",
       "3   ...           0        0        1        0        0        0        0   \n",
       "4   ...           0        0        0        0        0        0        0   \n",
       "5   ...           0        0        0        0        0        0        0   \n",
       "\n",
       "  pixel781 pixel782 pixel783  \n",
       "1        0        0        0  \n",
       "2        0        0        0  \n",
       "3        0        0        0  \n",
       "4        0        0        0  \n",
       "5        0        0        0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Rename train data for beeter understanding\n",
    "x_train=train_data\n",
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48999, 1)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import labels and drop ID\n",
    "y_train = pd.read_csv(\"C:\\\\Users\\\\soumyama\\\\Documents\\\\Python Scripts\\\\personal tutorial\\\\AV\\\\FashionMNIST\\\\train.csv\")\n",
    "y_train.head()\n",
    "y_train.drop(\"id\", axis=1, inplace=True)\n",
    "y_train=y_train.head(48999)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert train and test data into arrays\n",
    "x_train=np.array(x_train, dtype='float32')\n",
    "x_train=x_train/255\n",
    "#y_train=np.array(y_train, dtype='float32')\n",
    "\n",
    "#Split training data into train and validation data\n",
    "x_train, x_valid, y_train, y_valid =train_test_split(x_train, y_train, test_size=0.2, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x29b20d2d198>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Lets check an image\n",
    "plt.imshow(x_train[50,:].reshape((28,28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (39199, 28, 28, 1)\n",
      "x_valid shape: (9800, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "#Reshaping the train, validation and test data\n",
    "im_rows=28\n",
    "im_cols=28\n",
    "batch_size=512\n",
    "im_shape=(im_rows, im_cols, 1)\n",
    "\n",
    "x_train=x_train.reshape(x_train.shape[0], *im_shape)\n",
    "#x_test=x_test.reshape(x_test.shape[0], *im_shape)\n",
    "x_valid=x_valid.reshape(x_valid.shape[0], *im_shape)\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "#print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"x_valid shape: {}\".format(x_valid.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Convolutional Neural Network Model\n",
    "cnn_model= Sequential([\n",
    "    Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=im_shape),\n",
    "    MaxPooling2D(pool_size=2),\n",
    "    Dropout(0.2),\n",
    "    Flatten(),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.compile(loss='categorical_crossentropy', optimizer='Adam', mertics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_4 to have shape (10,) but got array with shape (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-3ac8e0582100>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcnn_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    953\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    954\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 955\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m    956\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    957\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    790\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 792\u001b[1;33m                 exception_prefix='target')\n\u001b[0m\u001b[0;32m    793\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    794\u001b[0m             \u001b[1;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    134\u001b[0m                             \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m                             str(data_shape))\n\u001b[0m\u001b[0;32m    137\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking target: expected dense_4 to have shape (10,) but got array with shape (1,)"
     ]
    }
   ],
   "source": [
    "cnn_model.fit(x_train, y_train, batch_size=batch_size, epochs=10, verbose=1, validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
